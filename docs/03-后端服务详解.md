# 后端服务详解

## 1. Python服务架构

### 1.1 服务概览

Python后端服务基于 **FastAPI** 框架构建，提供Excel数据处理、AI分析和报告生成功能。

**服务入口**: `python_service/main.py`

```
python_service/
├── main.py                    # FastAPI应用入口
├── excel_processor.py         # Excel文件处理器
├── requirements.txt           # Python依赖
├── Dockerfile                 # 容器构建文件
└── report_generator/          # 报告生成模块
    ├── __init__.py
    ├── agent.py               # AI Agent核心
    ├── data_analyzer.py       # 数据分析器
    ├── gene_editing_processor.py  # 基因编辑专用处理器
    ├── ppt_generator.py       # PPT生成器
    ├── report_generator.py    # Word报告生成器
    └── prompts.py             # AI提示词模板
```

### 1.2 技术栈

| 组件 | 版本 | 用途 |
|------|------|------|
| FastAPI | 0.115.6 | Web框架 |
| Uvicorn | 0.34.0 | ASGI服务器 |
| Pydantic | 2.10.4 | 数据验证 |
| LangChain | 0.3.14 | AI Agent框架 |
| OpenPyXL | 3.1.5 | Excel读写 |
| Pandas | 2.2.3 | 数据处理 |
| python-docx | 1.1.2 | Word文档生成 |
| python-pptx | 1.0.2 | PPT生成 |

---

## 2. FastAPI 应用

### 2.1 应用初始化

```python
# python_service/main.py
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uvicorn

app = FastAPI(
    title="Data Analysis Agent API",
    description="基因编辑数据分析与报告生成服务",
    version="1.0.0"
)

# CORS配置
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # 生产环境应限制具体域名
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### 2.2 API端点

#### 健康检查
```python
@app.get("/health")
async def health_check():
    """服务健康检查"""
    return {"status": "healthy", "service": "python-backend"}
```

#### Excel解析
```python
class ParseRequest(BaseModel):
    file_path: str
    user_id: str

class ParseResponse(BaseModel):
    success: bool
    data: dict
    stats: dict
    message: str = ""

@app.post("/parse-excel", response_model=ParseResponse)
async def parse_excel(request: ParseRequest):
    """
    解析Excel文件，提取基因编辑数据
    
    Args:
        request: 包含文件路径和用户ID
        
    Returns:
        解析后的数据和统计信息
    """
    try:
        from excel_processor import ExcelProcessor
        
        processor = ExcelProcessor(request.file_path)
        data = processor.parse()
        stats = processor.calculate_stats()
        
        return ParseResponse(
            success=True,
            data=data,
            stats=stats
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 数据简化
```python
class SimplifyRequest(BaseModel):
    file_path: str
    output_path: str
    options: dict = {}

@app.post("/simplify-excel")
async def simplify_excel(request: SimplifyRequest):
    """
    简化Excel数据，生成精简版本
    """
    try:
        from report_generator.gene_editing_processor import GeneEditingProcessor
        
        processor = GeneEditingProcessor(request.file_path)
        result = processor.generate_simplified_excel(request.output_path)
        
        return {
            "success": True,
            "output_path": result,
            "message": "简化完成"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 高亮处理
```python
@app.post("/highlight-excel")
async def highlight_excel(request: SimplifyRequest):
    """
    对Excel数据进行高亮标记
    """
    try:
        from report_generator.gene_editing_processor import GeneEditingProcessor
        
        processor = GeneEditingProcessor(request.file_path)
        result = processor.generate_highlighted_excel(request.output_path)
        
        return {
            "success": True,
            "output_path": result,
            "message": "高亮处理完成"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 报告生成
```python
class ReportRequest(BaseModel):
    file_id: str
    file_path: str
    report_type: str  # 'docx' or 'pptx'
    user_id: str
    options: dict = {}

@app.post("/generate-report")
async def generate_report(request: ReportRequest):
    """
    使用AI Agent生成分析报告
    
    Args:
        request: 报告生成请求参数
        
    Returns:
        生成的报告文件路径
    """
    try:
        from report_generator.agent import ReportAgent
        
        agent = ReportAgent()
        
        if request.report_type == 'docx':
            report_path = await agent.generate_word_report(
                file_path=request.file_path,
                user_id=request.user_id,
                options=request.options
            )
        elif request.report_type == 'pptx':
            report_path = await agent.generate_ppt_report(
                file_path=request.file_path,
                user_id=request.user_id,
                options=request.options
            )
        else:
            raise HTTPException(status_code=400, detail="不支持的报告类型")
        
        return {
            "success": True,
            "report_path": report_path,
            "message": "报告生成成功"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 文件下载
```python
@app.get("/download/{file_path:path}")
async def download_file(file_path: str):
    """下载生成的报告文件"""
    import os
    
    full_path = os.path.join("reports", file_path)
    
    if not os.path.exists(full_path):
        raise HTTPException(status_code=404, detail="文件不存在")
    
    return FileResponse(
        path=full_path,
        filename=os.path.basename(full_path),
        media_type="application/octet-stream"
    )
```

### 2.3 启动配置

```python
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # 开发模式热重载
        workers=4     # 生产模式多进程
    )
```

---

## 3. Excel处理器

### 3.1 基础Excel处理器

```python
# python_service/excel_processor.py
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font, Alignment
from typing import Dict, List, Any, Optional

class ExcelProcessor:
    """Excel文件处理器基类"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.workbook = None
        self.dataframes: Dict[str, pd.DataFrame] = {}
    
    def load(self) -> None:
        """加载Excel文件"""
        self.workbook = load_workbook(self.file_path)
        
        # 加载所有工作表为DataFrame
        for sheet_name in self.workbook.sheetnames:
            self.dataframes[sheet_name] = pd.read_excel(
                self.file_path, 
                sheet_name=sheet_name
            )
    
    def parse(self) -> Dict[str, Any]:
        """解析Excel数据"""
        if not self.workbook:
            self.load()
        
        result = {
            "sheets": [],
            "total_rows": 0,
            "total_columns": 0
        }
        
        for sheet_name, df in self.dataframes.items():
            sheet_data = {
                "name": sheet_name,
                "columns": df.columns.tolist(),
                "rows": df.shape[0],
                "data": df.to_dict(orient="records")
            }
            result["sheets"].append(sheet_data)
            result["total_rows"] += df.shape[0]
            result["total_columns"] = max(result["total_columns"], df.shape[1])
        
        return result
    
    def calculate_stats(self) -> Dict[str, Any]:
        """计算统计信息"""
        if not self.dataframes:
            self.load()
        
        stats = {
            "sheet_count": len(self.dataframes),
            "total_cells": 0,
            "numeric_columns": [],
            "text_columns": []
        }
        
        for sheet_name, df in self.dataframes.items():
            stats["total_cells"] += df.size
            
            for col in df.columns:
                if pd.api.types.is_numeric_dtype(df[col]):
                    stats["numeric_columns"].append(f"{sheet_name}.{col}")
                else:
                    stats["text_columns"].append(f"{sheet_name}.{col}")
        
        return stats
    
    def get_column_values(self, sheet_name: str, column: str) -> List[Any]:
        """获取指定列的所有值"""
        if sheet_name not in self.dataframes:
            raise ValueError(f"工作表 {sheet_name} 不存在")
        
        return self.dataframes[sheet_name][column].tolist()
    
    def filter_rows(self, sheet_name: str, condition: callable) -> pd.DataFrame:
        """根据条件过滤行"""
        if sheet_name not in self.dataframes:
            raise ValueError(f"工作表 {sheet_name} 不存在")
        
        df = self.dataframes[sheet_name]
        return df[df.apply(condition, axis=1)]
```

### 3.2 基因编辑专用处理器

```python
# python_service/report_generator/gene_editing_processor.py
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Border, Side, Alignment
from openpyxl.utils.dataframe import dataframe_to_rows
from typing import Dict, List, Tuple, Optional
import re

class GeneEditingProcessor:
    """基因编辑数据专用处理器"""
    
    # 突变类型定义
    MUTATION_TYPES = {
        'WT': '野生型',
        'HET': '杂合突变',
        'HOM': '纯合突变',
        'MOSAIC': '嵌合体',
        'DEL': '缺失',
        'INS': '插入',
        'SUB': '替换'
    }
    
    # 高亮颜色定义
    COLORS = {
        'WT': 'FFFFFF',      # 白色
        'HET': 'FFFF00',     # 黄色
        'HOM': 'FF6B6B',     # 红色
        'MOSAIC': 'FFA500',  # 橙色
        'DEL': 'ADD8E6',     # 浅蓝
        'INS': '90EE90',     # 浅绿
        'header': '4472C4',  # 深蓝(表头)
    }
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.df = None
        self.analysis_result = None
    
    def load_data(self) -> pd.DataFrame:
        """加载并预处理数据"""
        self.df = pd.read_excel(self.file_path)
        self._preprocess()
        return self.df
    
    def _preprocess(self) -> None:
        """数据预处理"""
        if self.df is None:
            return
        
        # 清理列名
        self.df.columns = [str(col).strip() for col in self.df.columns]
        
        # 填充空值
        self.df = self.df.fillna('')
        
        # 标准化突变类型
        if 'mutation_type' in self.df.columns:
            self.df['mutation_type'] = self.df['mutation_type'].apply(
                lambda x: str(x).upper().strip()
            )
    
    def analyze(self) -> Dict:
        """分析基因编辑数据"""
        if self.df is None:
            self.load_data()
        
        result = {
            'total_samples': len(self.df),
            'mutation_counts': {},
            'editing_efficiency': 0.0,
            'mutation_distribution': [],
            'sequence_analysis': {}
        }
        
        # 统计突变类型
        if 'mutation_type' in self.df.columns:
            mutation_counts = self.df['mutation_type'].value_counts().to_dict()
            result['mutation_counts'] = mutation_counts
            
            # 计算编辑效率 (非WT的比例)
            total = len(self.df)
            wt_count = mutation_counts.get('WT', 0)
            if total > 0:
                result['editing_efficiency'] = (total - wt_count) / total * 100
        
        # 突变分布
        for mut_type, count in result['mutation_counts'].items():
            result['mutation_distribution'].append({
                'type': mut_type,
                'name': self.MUTATION_TYPES.get(mut_type, mut_type),
                'count': count,
                'percentage': count / result['total_samples'] * 100
            })
        
        self.analysis_result = result
        return result
    
    def generate_simplified_excel(self, output_path: str) -> str:
        """生成简化版Excel"""
        if self.df is None:
            self.load_data()
        
        # 选择关键列
        key_columns = self._identify_key_columns()
        simplified_df = self.df[key_columns].copy()
        
        # 创建工作簿
        wb = Workbook()
        ws = wb.active
        ws.title = "简化数据"
        
        # 写入数据
        for r_idx, row in enumerate(dataframe_to_rows(simplified_df, index=False, header=True), 1):
            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx, value=value)
                
                # 表头样式
                if r_idx == 1:
                    cell.fill = PatternFill(start_color=self.COLORS['header'], 
                                           end_color=self.COLORS['header'], 
                                           fill_type='solid')
                    cell.font = Font(bold=True, color='FFFFFF')
                    cell.alignment = Alignment(horizontal='center')
        
        # 调整列宽
        for column in ws.columns:
            max_length = max(len(str(cell.value or '')) for cell in column)
            ws.column_dimensions[column[0].column_letter].width = min(max_length + 2, 50)
        
        wb.save(output_path)
        return output_path
    
    def generate_highlighted_excel(self, output_path: str) -> str:
        """生成带高亮的Excel"""
        if self.df is None:
            self.load_data()
        
        wb = Workbook()
        ws = wb.active
        ws.title = "高亮数据"
        
        # 写入数据并应用高亮
        for r_idx, row in enumerate(dataframe_to_rows(self.df, index=False, header=True), 1):
            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx, value=value)
                
                # 表头样式
                if r_idx == 1:
                    cell.fill = PatternFill(start_color=self.COLORS['header'],
                                           end_color=self.COLORS['header'],
                                           fill_type='solid')
                    cell.font = Font(bold=True, color='FFFFFF')
                else:
                    # 根据突变类型高亮
                    mutation_type = self._get_mutation_type_for_row(r_idx - 2)
                    if mutation_type and mutation_type in self.COLORS:
                        cell.fill = PatternFill(
                            start_color=self.COLORS[mutation_type],
                            end_color=self.COLORS[mutation_type],
                            fill_type='solid'
                        )
        
        # 添加边框
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        for row in ws.iter_rows():
            for cell in row:
                cell.border = thin_border
        
        wb.save(output_path)
        return output_path
    
    def _identify_key_columns(self) -> List[str]:
        """识别关键列"""
        key_patterns = [
            r'sample',
            r'name',
            r'id',
            r'mutation',
            r'type',
            r'sequence',
            r'result',
            r'efficiency'
        ]
        
        key_columns = []
        for col in self.df.columns:
            col_lower = col.lower()
            if any(re.search(pattern, col_lower) for pattern in key_patterns):
                key_columns.append(col)
        
        # 如果没有找到关键列，返回前5列
        if not key_columns:
            key_columns = self.df.columns[:5].tolist()
        
        return key_columns
    
    def _get_mutation_type_for_row(self, row_idx: int) -> Optional[str]:
        """获取指定行的突变类型"""
        if self.df is None or row_idx >= len(self.df):
            return None
        
        if 'mutation_type' in self.df.columns:
            return str(self.df.iloc[row_idx]['mutation_type']).upper()
        
        return None
    
    def extract_sequences(self) -> Dict[str, List[str]]:
        """提取序列信息"""
        if self.df is None:
            self.load_data()
        
        sequences = {
            'reference': [],
            'edited': [],
            'target': []
        }
        
        for col in self.df.columns:
            col_lower = col.lower()
            if 'ref' in col_lower or 'reference' in col_lower:
                sequences['reference'] = self.df[col].tolist()
            elif 'edit' in col_lower or 'mutant' in col_lower:
                sequences['edited'] = self.df[col].tolist()
            elif 'target' in col_lower:
                sequences['target'] = self.df[col].tolist()
        
        return sequences
    
    def calculate_editing_statistics(self) -> Dict:
        """计算编辑统计数据"""
        if self.analysis_result is None:
            self.analyze()
        
        stats = {
            'total_samples': self.analysis_result['total_samples'],
            'edited_samples': 0,
            'unedited_samples': 0,
            'editing_efficiency': self.analysis_result['editing_efficiency'],
            'mutation_breakdown': {}
        }
        
        for item in self.analysis_result['mutation_distribution']:
            if item['type'] == 'WT':
                stats['unedited_samples'] = item['count']
            else:
                stats['edited_samples'] += item['count']
            
            stats['mutation_breakdown'][item['type']] = {
                'count': item['count'],
                'percentage': item['percentage']
            }
        
        return stats
```

---

## 4. 数据分析器

### 4.1 分析器实现

```python
# python_service/report_generator/data_analyzer.py
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class AnalysisResult:
    """分析结果数据类"""
    summary: Dict[str, Any]
    statistics: Dict[str, Any]
    charts_data: List[Dict]
    insights: List[str]
    recommendations: List[str]

class DataAnalyzer:
    """数据分析器"""
    
    def __init__(self, data: pd.DataFrame):
        self.data = data
        self.result: Optional[AnalysisResult] = None
    
    def run_full_analysis(self) -> AnalysisResult:
        """执行完整分析"""
        summary = self._generate_summary()
        statistics = self._calculate_statistics()
        charts_data = self._prepare_charts_data()
        insights = self._extract_insights()
        recommendations = self._generate_recommendations()
        
        self.result = AnalysisResult(
            summary=summary,
            statistics=statistics,
            charts_data=charts_data,
            insights=insights,
            recommendations=recommendations
        )
        
        return self.result
    
    def _generate_summary(self) -> Dict[str, Any]:
        """生成数据摘要"""
        return {
            'total_records': len(self.data),
            'columns': list(self.data.columns),
            'data_types': {col: str(dtype) for col, dtype in self.data.dtypes.items()},
            'missing_values': self.data.isnull().sum().to_dict(),
            'memory_usage': self.data.memory_usage(deep=True).sum()
        }
    
    def _calculate_statistics(self) -> Dict[str, Any]:
        """计算统计数据"""
        stats = {}
        
        # 数值列统计
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            stats[col] = {
                'mean': self.data[col].mean(),
                'median': self.data[col].median(),
                'std': self.data[col].std(),
                'min': self.data[col].min(),
                'max': self.data[col].max(),
                'quartiles': self.data[col].quantile([0.25, 0.5, 0.75]).to_dict()
            }
        
        # 分类列统计
        categorical_cols = self.data.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            value_counts = self.data[col].value_counts()
            stats[col] = {
                'unique_count': self.data[col].nunique(),
                'top_values': value_counts.head(10).to_dict(),
                'mode': self.data[col].mode().iloc[0] if len(self.data[col].mode()) > 0 else None
            }
        
        return stats
    
    def _prepare_charts_data(self) -> List[Dict]:
        """准备图表数据"""
        charts = []
        
        # 数值分布直方图
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols[:3]:  # 限制前3个数值列
            hist, bin_edges = np.histogram(self.data[col].dropna(), bins=20)
            charts.append({
                'type': 'histogram',
                'title': f'{col} 分布',
                'data': {
                    'bins': bin_edges.tolist(),
                    'counts': hist.tolist()
                }
            })
        
        # 分类饼图
        categorical_cols = self.data.select_dtypes(include=['object']).columns
        for col in categorical_cols[:2]:  # 限制前2个分类列
            value_counts = self.data[col].value_counts().head(10)
            charts.append({
                'type': 'pie',
                'title': f'{col} 分布',
                'data': {
                    'labels': value_counts.index.tolist(),
                    'values': value_counts.values.tolist()
                }
            })
        
        return charts
    
    def _extract_insights(self) -> List[str]:
        """提取数据洞察"""
        insights = []
        
        # 数据规模
        insights.append(f"数据集包含 {len(self.data)} 条记录，{len(self.data.columns)} 个字段")
        
        # 缺失值分析
        missing = self.data.isnull().sum()
        if missing.any():
            cols_with_missing = missing[missing > 0]
            insights.append(f"发现 {len(cols_with_missing)} 个字段存在缺失值")
        
        # 数值异常
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            q1 = self.data[col].quantile(0.25)
            q3 = self.data[col].quantile(0.75)
            iqr = q3 - q1
            outliers = ((self.data[col] < q1 - 1.5 * iqr) | 
                       (self.data[col] > q3 + 1.5 * iqr)).sum()
            if outliers > 0:
                insights.append(f"字段 '{col}' 存在 {outliers} 个潜在异常值")
        
        return insights
    
    def _generate_recommendations(self) -> List[str]:
        """生成建议"""
        recommendations = []
        
        # 缺失值处理建议
        missing_ratio = self.data.isnull().sum() / len(self.data)
        high_missing = missing_ratio[missing_ratio > 0.3]
        if len(high_missing) > 0:
            recommendations.append(
                f"建议处理以下缺失率超过30%的字段: {', '.join(high_missing.index)}"
            )
        
        # 数据质量建议
        duplicate_count = self.data.duplicated().sum()
        if duplicate_count > 0:
            recommendations.append(f"发现 {duplicate_count} 条重复记录，建议去重处理")
        
        return recommendations
```

---

## 5. 错误处理与日志

### 5.1 异常处理

```python
# python_service/main.py
from fastapi import HTTPException
from fastapi.responses import JSONResponse
import logging
import traceback

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# 全局异常处理器
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Unhandled exception: {exc}")
    logger.error(traceback.format_exc())
    
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "服务器内部错误",
            "detail": str(exc) if app.debug else None
        }
    )

# 自定义异常
class DataProcessingError(Exception):
    """数据处理异常"""
    def __init__(self, message: str, details: dict = None):
        self.message = message
        self.details = details or {}
        super().__init__(self.message)

class ReportGenerationError(Exception):
    """报告生成异常"""
    def __init__(self, message: str, step: str = None):
        self.message = message
        self.step = step
        super().__init__(self.message)

@app.exception_handler(DataProcessingError)
async def data_processing_error_handler(request, exc: DataProcessingError):
    logger.warning(f"Data processing error: {exc.message}")
    return JSONResponse(
        status_code=400,
        content={
            "success": False,
            "error": exc.message,
            "details": exc.details
        }
    )
```

### 5.2 请求日志中间件

```python
from fastapi import Request
import time

@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    
    # 记录请求
    logger.info(f"Request: {request.method} {request.url}")
    
    response = await call_next(request)
    
    # 记录响应时间
    process_time = time.time() - start_time
    logger.info(f"Response: {response.status_code} ({process_time:.3f}s)")
    
    response.headers["X-Process-Time"] = str(process_time)
    return response
```

---

## 6. 依赖管理

### 6.1 requirements.txt

```txt
# Web框架
fastapi==0.115.6
uvicorn==0.34.0
python-multipart==0.0.20
pydantic==2.10.4

# AI/LLM
langchain==0.3.14
langchain-openai==0.3.0
langchain-community==0.3.14
openai==1.59.4

# 数据处理
pandas==2.2.3
openpyxl==3.1.5
numpy==2.2.1

# 文档生成
python-docx==1.1.2
python-pptx==1.0.2

# 工具库
python-dotenv==1.0.1
httpx==0.28.1
aiofiles==24.1.0
```

### 6.2 环境变量

```bash
# Python服务配置
PYTHON_SERVICE_HOST=0.0.0.0
PYTHON_SERVICE_PORT=8000

# OpenAI配置
OPENAI_API_KEY=sk-xxx
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4

# 通义千问配置 (可选)
DASHSCOPE_API_KEY=sk-xxx
QWEN_MODEL=qwen-max

# 文件存储
UPLOAD_DIR=./uploads
REPORT_DIR=./reports
MAX_FILE_SIZE=52428800  # 50MB
```

---

## 7. 相关文档

| 文档 | 描述 |
|------|------|
| [01-项目概述与架构](./01-项目概述与架构.md) | 项目整体架构 |
| [02-前端技术详解](./02-前端技术详解.md) | Next.js前端实现 |
| [05-AI Agent系统](./05-AI-Agent系统.md) | AI报告生成详解 |

---

*文档版本: 1.0.0 | 更新时间: 2026-02-10*
